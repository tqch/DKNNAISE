{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models/mnistmodel.pt'\n",
      "=> loaded checkpoint 'models/mnistmodel.pt' (epoch 55)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport DkNN,AISE,utils.utilities\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot   as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors,KNeighborsClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim         as optim\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision              import datasets \n",
    "from torchvision              import transforms\n",
    "\n",
    "from DkNN import CKNN\n",
    "import utilities\n",
    "from utils.utilities import *\n",
    "from mnist_model import CNN\n",
    "from attack import PGD\n",
    "from AISE import *\n",
    "\n",
    "device = torch.device('cuda')\n",
    "config = utilities.config_to_namedtuple(utilities.get_config('config_mnist.json'))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./datasets', train=True, download=False, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "]))\n",
    "mnist_testset = datasets.MNIST(root='./datasets', train=False, download=False, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset,\n",
    "    shuffle = True,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset,\n",
    "    shuffle = False,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "filename = 'models/mnistmodel.pt'\n",
    "model = CNN().to(device)\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "    checkpoint = torch.load(filename,map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(filename, checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=6272, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_space(net, n_layers, inputs, labels, device, batch_size=128):\n",
    "\n",
    "    conv_features = [[] for _ in range(n_layers)]\n",
    "    targets       = []\n",
    "    predictions   = []\n",
    "    print('\\tRunning predictions')\n",
    "    net.eval()\n",
    "    for ind in range(0,inputs.size(0),batch_size):\n",
    "        X,y = inputs[ind:ind+batch_size],labels[ind:ind+batch_size]\n",
    "        *out_convs, out = net(X.to(device))\n",
    "        y_pred = torch.max(out,1)[1]\n",
    "        for i, out_conv in enumerate(out_convs):\n",
    "            conv_feat = out_conv.view(out_conv.size(0), -1).detach().cpu()\n",
    "            conv_features[i].append(conv_feat)\n",
    "        targets.append(y.numpy())\n",
    "        predictions.append(y_pred.detach().cpu().numpy())\n",
    "    print('\\tConcatenating results')\n",
    "    conv_features = [torch.cat(out_convs) for out_convs in conv_features]\n",
    "    targets       = np.concatenate(targets)\n",
    "    predictions   = np.concatenate(predictions)\n",
    "\n",
    "    return conv_features, targets, predictions\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-16GB'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRunning predictions\n",
      "\tConcatenating results\n",
      "The accuracy of plain cnn under PGD attacks is: 0.175000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "ind_full = np.arange(60000)\n",
    "np.random.shuffle(ind_full)\n",
    "ind_partial = ind_full[:2000]\n",
    "X_train_partial = mnist_trainset.data[ind_partial].unsqueeze(1)/255.\n",
    "y_train_partial = mnist_trainset.targets[ind_partial]\n",
    "X_hidden_partial,_,_ = feature_space(model,4,X_train_partial,y_train_partial,device)\n",
    "ind_eval = ind_full[2000:2200]\n",
    "X_eval = mnist_trainset.data[ind_eval].unsqueeze(1)/255.\n",
    "y_eval = mnist_trainset.targets[ind_eval]\n",
    "X_adv = PGD(eps=40/255.,sigma=20/255.,nb_iter=20,DEVICE=device).attack_batch(model,X_eval.to(device),y_eval.to(device),batch_size=64)\n",
    "*_,out = model(X_adv)\n",
    "y_pred_adv = torch.max(out,1)[1]\n",
    "print('The accuracy of plain cnn under PGD attacks is: {:f}'.format((y_eval.numpy()==y_pred_adv.detach().cpu().numpy()).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/X_adv_2000.pkl\",\"wb\") as f:\n",
    "    pickle.dump(X_adv.cpu().numpy(),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden representation found!\n",
      "Concatenating the hidden representations...\n",
      "Building query objects for 10 classes 2000 samples...done!\n",
      "4 hyper-parameters found!\n",
      "24 combinations to be searched\n",
      "#1: combine_prob=0.5,n_class=0,layer_dims=[],max_generation=20\n",
      "Building one single query object 2000 samples...done!\n",
      "Clonal expansion starts...\n",
      "Searching 10 naive B cells for each of 200 antigens...done!\n",
      "Affinity maturation process starts with population of 1000...\n",
      "Memory & plasma B cells generated!\n",
      "10000 plasma B cells and 40000 memory generated!\n",
      "acc: 0.825\n",
      "Total running time is 81.56326937675476\n",
      "\n",
      "#2: combine_prob=0.5,n_class=0,layer_dims=[],max_generation=30\n",
      "Building one single query object 2000 samples...done!\n",
      "Clonal expansion starts...\n",
      "Searching 10 naive B cells for each of 200 antigens...done!\n",
      "Affinity maturation process starts with population of 1000...\n"
     ]
    }
   ],
   "source": [
    "aise = AISE(X_train_partial,y_train_partial,X_hidden_partial,model=model)\n",
    "# grid search\n",
    "param_dict = {\n",
    "# 'mut_range':list(zip(itertools.repeat(.1),[.15,.3,.4])),\n",
    "# 'mut_prob':list(zip(itertools.repeat(.1),[.15,.3,.4])),\n",
    "'combine_prob':[.5,.7],\n",
    "'n_class':[0,10],\n",
    "'layer_dims':[[],[0,],[1,]],\n",
    "'max_generation':[20,30],\n",
    "}\n",
    "gs = GridSearch(aise,param_dict)\n",
    "result_dict = gs.run(X_adv.cpu(),y_eval.numpy())\n",
    "with open(\"results/result_dict_2000.pkl\",\"wb\") as f:\n",
    "    pickle.dump(result_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_partial.flatten(start_dim=1).numpy(),y_train_partial.numpy())\n",
    "knn_pred = knn.predict(X_adv.cpu().numpy().reshape(X_adv.size(0),-1))\n",
    "print('The accuaracy of plain KNN against adversarial samples is: {}'.format((knn_pred==y_eval.numpy()).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,200))\n",
    "# for k,v in result_dict.items():\n",
    "# #     plt.suptitle(k)\n",
    "#     for i,aise_pred in enumerate(v[\"y_pred\"]):\n",
    "#         ax = plt.subplot(20,3,3*i+1)\n",
    "#         ax.imshow(X_eval[i].cpu().numpy().reshape(28,28))\n",
    "#         ax.axis('off')\n",
    "#         ax = plt.subplot(20,3,3*i+2)\n",
    "#         ax.imshow(X_adv[i].cpu().numpy().reshape(28,28))\n",
    "#         ax.axis('off')\n",
    "#         ax = plt.subplot(20,3,3*i+3)\n",
    "#         ax.annotate('AISE pred: {} vs KNN pred: {}'.format(\n",
    "#             aise_pred,knn_pred[i]),xy=(.5,.5),xycoords='axes fraction',ha='center',va='center',fontsize=36)\n",
    "#         ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "ind_full = np.arange(60000)\n",
    "np.random.shuffle(ind_full)\n",
    "ind_partial = ind_full[:5000]\n",
    "X_train_partial = mnist_trainset.data[ind_partial].unsqueeze(1)/255.\n",
    "y_train_partial = mnist_trainset.targets[ind_partial]\n",
    "X_hidden_partial,_,_ = feature_space(model,4,X_train_partial,y_train_partial,device)\n",
    "ind_eval = ind_full[5000:5500]\n",
    "X_eval = mnist_trainset.data[ind_eval].unsqueeze(1)/255.\n",
    "y_eval = mnist_trainset.targets[ind_eval]\n",
    "X_adv = PGD(eps=40/255.,sigma=20/255.,nb_iter=20,DEVICE=device).attack_batch(model,X_eval.to(device),y_eval.to(device),batch_size=64)\n",
    "*_,out = model(X_adv)\n",
    "y_pred_adv = torch.max(out,1)[1]\n",
    "print('The accuracy of plain cnn under PGD attacks is: {:f}'.format((y_eval.numpy()==y_pred_adv.detach().cpu().numpy()).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/X_adv_5000.pkl\",\"wb\") as f:\n",
    "    pickle.dump(X_adv.cpu().numpy(),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aise = AISE(X_train_partial,y_train_partial,X_hidden_partial,model=model)\n",
    "# grid search\n",
    "param_dict = {\n",
    "# 'mut_range':list(zip(itertools.repeat(.1),[.15,.3,.4])),\n",
    "# 'mut_prob':list(zip(itertools.repeat(.1),[.15,.3,.4])),\n",
    "'combine_prob':[.5,.7],\n",
    "'n_class':[0,10],\n",
    "'layer_dims':[[],[0,],[1,]],\n",
    "'max_generation':[20,30],\n",
    "}\n",
    "gs = GridSearch(aise,param_dict)\n",
    "result_dict = gs.run(X_adv.cpu(),y_eval.numpy())\n",
    "with open(\"results/result_dict_5000.pkl\",\"wb\") as f:\n",
    "    pickle.dump(result_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_partial.flatten(start_dim=1).numpy(),y_train_partial.numpy())\n",
    "knn_pred = knn.predict(X_adv.cpu().numpy().reshape(X_adv.size(0),-1))\n",
    "print('The accuaracy of plain KNN against adversarial samples is: {}'.format((knn_pred==y_eval.numpy()).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
