{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "=> loading checkpoint 'models/mnistmodel.pt'\n",
      "=> loaded checkpoint 'models/mnistmodel.pt' (epoch 55)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport DkNN,AISE\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot   as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors,KNeighborsClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim         as optim\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision              import datasets \n",
    "from torchvision              import transforms\n",
    "\n",
    "from DkNN import CKNN\n",
    "import utilities\n",
    "from mnist_model import CNN\n",
    "from attack import PGD\n",
    "from AISE import *\n",
    "\n",
    "device = torch.device('cuda')\n",
    "config = utilities.config_to_namedtuple(utilities.get_config('config_mnist.json'))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./datasets', train=True, download=False, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "]))\n",
    "mnist_testset = datasets.MNIST(root='./datasets', train=False, download=False, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset,\n",
    "    shuffle = True,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset,\n",
    "    shuffle = False,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "filename = 'models/mnistmodel.pt'\n",
    "model = CNN().to(device)\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "    checkpoint = torch.load(filename,map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(filename, checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=6272, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_space(cnnmod, num_rep, inputs, labels, device, batch_size=128):\n",
    "\n",
    "    conv_features = [[] for _ in range(num_rep)]\n",
    "    targets       = []\n",
    "    predictions   = []\n",
    "    print('\\tRunning predictions')\n",
    "    cnnmod.eval()\n",
    "    for ind in range(0,inputs.size(0),batch_size):\n",
    "        X,y = inputs[ind:ind+batch_size],labels[ind:ind+batch_size]\n",
    "        *out_convs, out = cnnmod(X.to(device))\n",
    "        y_pred = torch.max(out,1)[1]\n",
    "        for i, out_conv in enumerate(out_convs):\n",
    "            conv_feat = out_conv.view(out_conv.size(0), -1).detach().cpu().numpy()\n",
    "            conv_features[i].append(conv_feat)\n",
    "        targets.append(y.numpy())\n",
    "        predictions.append(y_pred.detach().cpu().numpy())\n",
    "    print('\\tConcatenating results')\n",
    "    conv_features = [np.concatenate(out_convs) for out_convs in conv_features]\n",
    "    targets       = np.concatenate(targets)\n",
    "    predictions   = np.concatenate(predictions)\n",
    "\n",
    "    return conv_features, targets, predictions\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "ind_full = np.arange(60000)\n",
    "np.random.shuffle(ind_full)\n",
    "ind_partial = ind_full[:2000]\n",
    "X_train_partial = mnist_trainset.data[ind_partial].unsqueeze(1)/255.\n",
    "y_train_partial = mnist_trainset.targets[ind_partial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_eval = ind_full[2000:2100]\n",
    "X_eval = mnist_trainset.data[ind_eval].unsqueeze(1)/255.\n",
    "y_eval = mnist_trainset.targets[ind_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of plain cnn under PGD attacks is: 0.160000\n"
     ]
    }
   ],
   "source": [
    "X_adv = PGD(eps=40/255.,sigma=20/255.,DEVICE=device).attack_batch(model,X_eval.to(device),y_eval.to(device),batch_size=32)\n",
    "*_,out = model(X_adv)\n",
    "y_pred_adv = torch.max(out,1)[1]\n",
    "print('The accuracy of plain cnn under PGD attacks is: {:f}'.format((y_eval.numpy()==y_pred_adv.detach().cpu().numpy()).mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRunning predictions\n",
      "\tConcatenating results\n"
     ]
    }
   ],
   "source": [
    "X_hidden_partial, _, _ = feature_space(model, 4, X_train_partial, y_train_partial, device, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building query objects for 10 classes 2000 samples...done!\n",
      "Clonal expansion starts...\n",
      "Searching 10 naive B cells per class for each of 100 antigens...done!\n",
      "Affinity maturation process starts with population of 1000...\n",
      "Memory & plasma B cells generated!\n",
      "5000 plasma B cells and 20000 memory generated!\n",
      "Total running time is 89.21562671661377s.\n",
      "The accuracy of majority voting by AISE against adversarial samples is: 0.88\n",
      "The accuaracy of plain KNN against adversarial samples is: 0.84\n"
     ]
    }
   ],
   "source": [
    "aise = AISE(X_train_partial,y_train_partial,model=model,fitness_function=neg_l2_dist)\n",
    "start_time = time.time()\n",
    "mem_bcs,mem_labs,pla_bcs,pla_labs,fit_log = aise.clonal_expansion(X_adv.cpu(),return_log=True)\n",
    "end_time = time.time()\n",
    "print(\"Total running time is {}s.\".format(end_time-start_time))\n",
    "y_pred = np.array(list(map(lambda x: Counter(x).most_common(1)[0][0],pla_labs.numpy())))\n",
    "print('The accuracy of majority voting by AISE against adversarial samples is: {}'.format((y_pred==y_eval.numpy()).mean()))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_partial.flatten(start_dim=1).numpy(),y_train_partial.numpy())\n",
    "y_pred = knn.predict(X_adv.cpu().numpy().reshape(X_adv.size(0),-1))\n",
    "print('The accuaracy of plain KNN against adversarial samples is: {}'.format((y_pred==y_eval.numpy()).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building query objects for 10 classes 2000 samples...done!\n",
      "Clonal expansion starts...\n",
      "Searching 10 naive B cells per class for each of 100 antigens...done!\n",
      "Affinity maturation process starts with population of 1000...\n",
      "Memory & plasma B cells generated!\n",
      "5000 plasma B cells and 20000 memory generated!\n",
      "Total running time is 90.04372024536133s.\n",
      "The accuracy of majority voting by AISE against adversarial samples is: 0.57\n",
      "The accuaracy of plain KNN against adversarial samples is: 0.84\n"
     ]
    }
   ],
   "source": [
    "aise = AISE(X_train_partial,y_train_partial,model=model)\n",
    "start_time = time.time()\n",
    "mem_bcs,mem_labs,pla_bcs,pla_labs,fit_log = aise.clonal_expansion(X_adv.cpu(),return_log=True)\n",
    "end_time = time.time()\n",
    "print(\"Total running time is {}s.\".format(end_time-start_time))\n",
    "y_pred = np.array(list(map(lambda x: Counter(x).most_common(1)[0][0],pla_labs.numpy())))\n",
    "print('The accuracy of majority voting by AISE against adversarial samples is: {}'.format((y_pred==y_eval.numpy()).mean()))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_partial.flatten(start_dim=1).numpy(),y_train_partial.numpy())\n",
    "y_pred = knn.predict(X_adv.cpu().numpy().reshape(X_adv.size(0),-1))\n",
    "print('The accuaracy of plain KNN against adversarial samples is: {}'.format((y_pred==y_eval.numpy()).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aise = AISE(X_train_partial,y_train_partial,model=model,fitness_function=neg_l2_dist,requires_init=True)\n",
    "start_time = time.time()\n",
    "mem_bcs,mem_labs,pla_bcs,pla_labs,fit_log = aise.clonal_expansion(X_adv.cpu(),return_log=True)\n",
    "end_time = time.time()\n",
    "print(\"Total running time is {}s.\".format(end_time-start_time))\n",
    "y_pred = np.array(list(map(lambda x: Counter(x).most_common(1)[0][0],pla_labs.numpy())))\n",
    "print('The accuracy of majority voting by AISE against adversarial samples is: {}'.format((y_pred==y_eval.numpy()).mean()))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_partial.flatten(start_dim=1).numpy(),y_train_partial.numpy())\n",
    "y_pred = knn.predict(X_adv.cpu().numpy().reshape(X_adv.size(0),-1))\n",
    "print('The accuaracy of plain KNN against adversarial samples is: {}'.format((y_pred==y_eval.numpy()).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
