{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwfmwijqnVjr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot   as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors,KNeighborsClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim         as optim\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision              import datasets \n",
    "from torchvision              import transforms\n",
    "\n",
    "from DkNN import CKNN\n",
    "import utilities\n",
    "from mnist_model import CNN\n",
    "from attack import PGD\n",
    "\n",
    "class GenAdapt:\n",
    "    '''\n",
    "    core component of AISE B-cell generation\n",
    "    '''\n",
    "\n",
    "    def __init__(self, mut_range, mut_prob, combine_rate=0.5, hybrid_rate=0.5, mode='random'):\n",
    "        self.mut_range = mut_range\n",
    "        self.mut_prob = mut_prob\n",
    "        self.combine_rate = combine_rate\n",
    "        self.hybrid_rate = hybrid_rate\n",
    "        self.mode = mode\n",
    "\n",
    "    def crossover(self, base1, base2, select_prob):\n",
    "        assert base1.ndim == 2 and base2.ndim == 2, \"Number of dimensions should be 2\"\n",
    "        crossover_mask = torch.rand(base1.size()) < select_prob\n",
    "        return torch.where(crossover_mask, base1, base2)\n",
    "\n",
    "    def mutate_random(self, base):\n",
    "        mut = 2 * torch.rand_like(base) - 1  # uniform (-1,1)\n",
    "        mut = self.mut_range * mut\n",
    "        mut_mask = torch.rand(base.size()) < self.mut_prob\n",
    "        child = torch.where(mut_mask, base, base + mut)\n",
    "        return torch.clamp(child, 0, 1)\n",
    "\n",
    "    def mutate_guided(self, base, target):\n",
    "        guidance = target - base\n",
    "        mut = (2 * torch.rand_like(base) - 1) * guidance * self.mut_range  # uniform (-1,1)\n",
    "        mut_mask = torch.rand(base.size()) < self.mut_prob\n",
    "        child = torch.where(mut_mask, base, base + mut)\n",
    "        return torch.clamp(child, 0, 1)\n",
    "\n",
    "    def mutate_combined(self, base, target):\n",
    "        guidance = target - base\n",
    "        mut_random = 2 * torch.rand_like(base) - 1  # uniform (-1,1)\n",
    "        mut_guided = (2 * torch.rand_like(base) - 1) * guidance\n",
    "        # when self.combine_rate is set 0, it degenerate into random mutate\n",
    "        combine_mask = torch.rand(base.size()) < self.combine_rate\n",
    "        mut = self.mut_range * torch.where(combine_mask, mut_guided, mut_random)\n",
    "        mut_mask = torch.rand(base.size()) < self.mut_prob\n",
    "        child = torch.where(mut_mask, base, base + mut)\n",
    "        return torch.clamp(child, 0, 1)\n",
    "\n",
    "    def hybrid(self, base, target):\n",
    "        child = self.crossover(base, target, self.hybrid_rate)\n",
    "        child = self.mutate_guided(child, target - base)\n",
    "        return child\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        if self.mode == \"random\":\n",
    "            base, *_ = args\n",
    "            return self.mutate_random(base)\n",
    "        else:\n",
    "            assert len(args) == 2\n",
    "            base, target = args\n",
    "            if self.mode == \"guided\":\n",
    "                return self.mutate_guided(base, target)\n",
    "            if self.mode == \"combined\":\n",
    "                return self.mutate_combined(base, target)\n",
    "            if self.mode == \"hybrid\":\n",
    "                return self.hybrid(base, target)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported mutation type!\")\n",
    "\n",
    "    def proliferate(self, p1, p2, select_prob, mut_prob):\n",
    "        pass\n",
    "\n",
    "def gram_matrix(input, batch_size=64):\n",
    "    a, b, c, d = input.size()  # a=batch size(=1)\n",
    "    # b=number of feature maps\n",
    "    # (c,d)=dimensions of a f. map (N=c*d)\n",
    "    \n",
    "    G = []\n",
    "    for i in range(0,a,batch_size):\n",
    "        temp_features = input[i:i+batch_size]  # resise F_XL into \\hat F_XL\n",
    "        temp_features = temp_features.view(temp_features.size(0)*b,c*d)\n",
    "        temp_G = torch.mm(temp_features, temp_features.t()).view(-1,b,b)  # compute the gram product\n",
    "        G.append(temp_G)\n",
    "    # we 'normalize' the values of the gram matrix\n",
    "    # by dividing by the number of element in each feature maps.\n",
    "    return torch.cat(G,dim=0).div(b * c * d)\n",
    "\n",
    "class L2NearestNeighbors(NearestNeighbors):\n",
    "    '''\n",
    "    compatible query object class for euclidean distance\n",
    "    '''\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.kneighbors(X, return_distance=False)\n",
    "\n",
    "\n",
    "def recip_l2_dist(X, Y, eps=1e-6):\n",
    "    correction = np.power(euclidean_distances(X, Y), 2) + eps\n",
    "    return 1 / np.sqrt(correction)\n",
    "\n",
    "\n",
    "def neg_l2_dist(X, Y):\n",
    "    return -euclidean_distances(X, Y)\n",
    "\n",
    "def feature_space(net, n_layers, inputs, device, batch_size=128):\n",
    "\n",
    "    conv_features = [[] for _ in range(n_layers)]\n",
    "    net.eval()\n",
    "    for ind in range(0,inputs.size(0),batch_size):\n",
    "        X = inputs[ind:ind+batch_size]\n",
    "        *out_convs, out = net(X.to(device))\n",
    "        for i, out_conv in enumerate(out_convs):\n",
    "            conv_feat = out_conv.detach().cpu()\n",
    "            conv_features[i].append(conv_feat)\n",
    "    print('\\tConcatenating results')\n",
    "    conv_features = [torch.cat(out_convs) for out_convs in conv_features]\n",
    "\n",
    "    return conv_features\n",
    "\n",
    "class AISE:\n",
    "    '''\n",
    "    implement the Adaptive Immune System Emulation\n",
    "    '''\n",
    "\n",
    "    def __init__(self, X_orig, y_orig, X_hidden=[], weights=[], model=None, input_shape=None,\n",
    "                 device=torch.device(\"cuda\"), n_class=10, n_neighbors=10, query_class=\"l2\", norm_order=2,\n",
    "                 fitness_function=recip_l2_dist, sampling_temperature=.3, max_generation=20, requires_init=False,\n",
    "                 mut_range=(.1, .3), mut_prob=(.1, .3), mut_mode=\"combined\", combine_rate=0.7, hybrid_rate=.9,\n",
    "                 decay=(.9, .9), n_population=1000, memory_threshold=.25, plasma_threshold=.05, return_log=True):\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        if input_shape is None:\n",
    "            self.input_shape = tuple(X_orig.shape[1:])  # mnist: (1,28,28)\n",
    "        else:\n",
    "            self.input_shape = input_shape\n",
    "\n",
    "        self.X_orig = X_orig\n",
    "        self.y_orig = y_orig\n",
    "        self.X_cat = self._transform_to_inner_repr(self.X_orig)\n",
    "\n",
    "        self.n_class = n_class\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.query_class = query_class\n",
    "        self.norm_order = norm_order\n",
    "        self.fitness_func = fitness_function\n",
    "        self.sampl_temp = sampling_temperature\n",
    "        self.max_generation = max_generation\n",
    "        self.n_population = self.n_class * self.n_neighbors\n",
    "        self.requires_init = requires_init\n",
    "\n",
    "        self.mut_range = mut_range\n",
    "        self.mut_prob = mut_prob\n",
    "\n",
    "        if isinstance(mut_range, float):\n",
    "            self.mut_range = (mut_range, mut_range)\n",
    "        if isinstance(mut_prob, float):\n",
    "            self.mut_prob = (mut_prob, mut_prob)\n",
    "\n",
    "        self.mut_mode = mut_mode\n",
    "        self.combine_rate = combine_rate\n",
    "        self.hybrid_rate = hybrid_rate\n",
    "        self.decay = decay\n",
    "        self.n_population = n_population\n",
    "        self.plasma_thres = plasma_threshold\n",
    "        self.memory_thres = memory_threshold\n",
    "        self.return_log = return_log\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        self.X_cat = self.transform(self.X_orig, *self.X_hidden)\n",
    "        self.query_objects = self._build_all_query_objects()\n",
    "\n",
    "    def _build_class_query_object(self, class_label=-1):\n",
    "        if class_label + 1:\n",
    "            X_class = self.X_cat[self.y_orig == class_label]\n",
    "        else:\n",
    "            X_class = self.X_cat\n",
    "        if self.query_class == \"l2\":\n",
    "            query_object = L2NearestNeighbors(n_neighbors=self.n_neighbors).fit(X_class)\n",
    "        return query_object\n",
    "\n",
    "    def _build_all_query_objects(self):\n",
    "        if self.n_class:\n",
    "            print(\"Building query objects for {} classes {} samples...\".format(self.n_class, self.X_orig.size(0)),\n",
    "                  end=\"\")\n",
    "            query_objects = [self._build_class_query_object(i) for i in range(self.n_class)]\n",
    "            print(\"done!\")\n",
    "        else:\n",
    "            print(\"Building one single query object {} samples...\".format(self.X_orig.size(0)), end=\"\")\n",
    "            query_objects = [self._build_class_query_object()]\n",
    "            print(\"done!\")\n",
    "        return query_objects\n",
    "\n",
    "    def _query_nns_ind(self, Q):\n",
    "        assert Q.ndim == 2, \"Q: 2d array-like (n_queries,n_features)\"\n",
    "        if self.n_class:\n",
    "            print(\"Searching {} naive B cells per class for each of {} antigens...\".format(self.n_neighbors, Q.size(0)),\n",
    "                  end=\"\")\n",
    "            rel_ind = [query_obj(Q) for query_obj in self.query_objects]\n",
    "            abs_ind = []\n",
    "            for c in range(self.n_class):\n",
    "                class_ind = np.where(self.y_orig.numpy() == c)[0]\n",
    "                abs_ind.append(class_ind[rel_ind[c]])\n",
    "            print(\"done!\")\n",
    "        else:\n",
    "            print(\"Searching {} naive B cells for each of {} antigens...\".format(self.n_neighbors, Q.size(0)),\n",
    "                  end=\"\")\n",
    "            abs_ind = [query_obj(Q) for query_obj in self.query_objects]\n",
    "            print('done!')\n",
    "        return abs_ind\n",
    "\n",
    "    def _transform_to_inner_repr(self, X):\n",
    "        '''\n",
    "        transform b cells and antigens into inner representations of AISE\n",
    "        '''\n",
    "        X_hidden = []\n",
    "        out_hidden = feature_space(model, 4, X, self.device, 128)\n",
    "        for out in out_hidden:\n",
    "            X_hidden.append(gram_matrix(out).cpu().flatten(start_dim=1))\n",
    "        \n",
    "        return torch.cat(X_hidden,dim=0)\n",
    "\n",
    "    def generate_b_cells(self, ant, ant_tran, nbc_ind, y_ant=None):\n",
    "        assert ant_tran.ndim == 2, \"ant: 2d tensor (n_antigens,n_features)\"\n",
    "        mem_bc_batch = []\n",
    "        pla_bc_batch = []\n",
    "        mem_lab_batch = []\n",
    "        pla_lab_batch = []\n",
    "        print(\"Affinity maturation process starts with population of {}...\".format(self.n_population))\n",
    "        ant_logs = []  # store the history dict in terms of metrics for antigens\n",
    "        for n in range(ant.size(0)):\n",
    "            genadapt = GenAdapt(self.mut_range[1], self.mut_prob[1], self.combine_rate,\n",
    "                                self.hybrid_rate, mode=self.mut_mode)\n",
    "            curr_gen = torch.cat([self.X_orig[ind[n]] for ind in nbc_ind])  # naive b cells\n",
    "            # labels = np.repeat(np.arange(self.n_class), self.n_neighbors)\n",
    "            labels = np.concatenate([self.y_orig[ind[n]] for ind in nbc_ind])\n",
    "            if self.requires_init:\n",
    "                assert self.n_population % (\n",
    "                        self.n_class * self.n_neighbors) == 0, \\\n",
    "                    \"n_population should be divisible by the product of n_class and n_neighbors\"\n",
    "                curr_gen = curr_gen.repeat((self.n_population // (self.n_class * self.n_neighbors), 1))\n",
    "                curr_gen = genadapt.mutate_random(curr_gen)  # initialize *NOTE: torch.Tensor.repeat <> numpy.repeat\n",
    "                labels = np.tile(labels, self.n_population // (self.n_class * self.n_neighbors))\n",
    "            curr_inner_repr = self._transform_to_inner_repr(curr_gen)\n",
    "            fitness_score = torch.Tensor(self.fitness_func(ant_tran[n].unsqueeze(0), curr_inner_repr)[0])\n",
    "            best_pop_fitness = float('-inf')\n",
    "            decay_coef = (1., 1.)\n",
    "            num_plateau = 0\n",
    "            ant_log = dict()  # history log for each antigen\n",
    "            fitness_pop_hist = []\n",
    "            if y_ant is not None:\n",
    "                fitness_true_class_hist = []\n",
    "                pct_true_class_hist = []\n",
    "            for i in range(self.max_generation):\n",
    "                # print(\"Antigen {} Generation {}\".format(n,i))\n",
    "                survival_prob = F.softmax(fitness_score / self.sampl_temp, dim=-1)\n",
    "                parents_ind = Categorical(probs=survival_prob).sample((self.n_population,))\n",
    "                parents = curr_gen[parents_ind]\n",
    "                curr_gen = genadapt(parents, ant[n].unsqueeze(0))\n",
    "                curr_inner_repr = self._transform_to_inner_repr(curr_gen)\n",
    "                labels = labels[parents_ind.numpy()]\n",
    "                fitness_score = torch.Tensor(self.fitness_func(ant_tran[n].unsqueeze(0), curr_inner_repr)[0])\n",
    "                pop_fitness = fitness_score.sum().item()\n",
    "                # logging\n",
    "                fitness_pop_hist.append(pop_fitness)\n",
    "                if y_ant is not None:\n",
    "                    true_class_fitness = fitness_score[labels == y_ant[n]].sum().item()\n",
    "                    fitness_true_class_hist.append(true_class_fitness)\n",
    "                    true_class_pct = (labels == y_ant[n]).astype('float').mean().item()\n",
    "                    pct_true_class_hist.append(true_class_pct)\n",
    "                # adaptive shrinkage of certain hyper-parameters\n",
    "                if self.decay:\n",
    "                    assert len(self.decay) == 2\n",
    "                    if pop_fitness < best_pop_fitness:\n",
    "                        if num_plateau >= max(math.log(self.mut_range[0] / self.mut_range[1], self.decay[0]),\n",
    "                                              math.log(self.mut_prob[0] / self.mut_prob[1], self.decay[1])):\n",
    "                            # early stop\n",
    "                            break\n",
    "                        decay_coef = tuple(decay_coef[i] * self.decay[i] for i in range(2))\n",
    "                        num_plateau += 1\n",
    "                        genadapt = GenAdapt(max(self.mut_range[0], self.mut_range[1] * decay_coef[0]),\n",
    "                                            max(self.mut_prob[0], self.mut_prob[1] * decay_coef[1]),\n",
    "                                            self.combine_rate, self.hybrid_rate, mode=self.mut_mode)\n",
    "                    else:\n",
    "                        best_pop_fitness = pop_fitness\n",
    "            # fitness_score = torch.Tensor(self.fitness_func(ant_tran[n].unsqueeze(0),curr_inner_repr)[0])\n",
    "            _, fitness_rank = torch.sort(fitness_score)\n",
    "            ant_log[\"fitness_pop\"] = fitness_pop_hist\n",
    "            if y_ant is not None:\n",
    "                ant_log[\"fitness_true_class\"] = fitness_true_class_hist\n",
    "                ant_log[\"pct_true_class\"] = pct_true_class_hist\n",
    "            pla_bc_batch.append(curr_gen[fitness_rank[-int(self.plasma_thres * self.n_population):]])\n",
    "            pla_lab_batch.append(labels[fitness_rank[-int(self.plasma_thres * self.n_population):]])\n",
    "            mem_bc_batch.append(curr_gen[fitness_rank[-int(self.memory_thres * self.n_population):-int(\n",
    "                self.plasma_thres * self.n_population)]])\n",
    "            mem_lab_batch.append(labels[fitness_rank[-int(self.memory_thres * self.n_population):-int(\n",
    "                self.plasma_thres * self.n_population)]])\n",
    "            ant_logs.append(ant_log)\n",
    "        print(\"Memory & plasma B cells generated!\")\n",
    "        return torch.cat(mem_bc_batch), torch.tensor(np.stack(mem_lab_batch)), \\\n",
    "               torch.cat(pla_bc_batch), torch.tensor(np.stack(pla_lab_batch)), \\\n",
    "               ant_logs\n",
    "\n",
    "    def clonal_expansion(self, ant, y_ant=None, return_log=False):\n",
    "        print(\"Clonal expansion starts...\")\n",
    "        ant_tran = self._transform_to_inner_repr(ant, reshape=False)\n",
    "        nbc_ind = self._query_nns_ind(ant_tran)\n",
    "        mem_bcs, mem_labs, pla_bcs, pla_labs, ant_logs = self.generate_b_cells(ant.flatten(start_dim=1), ant_tran,\n",
    "                                                                               nbc_ind, y_ant)\n",
    "        print(\"{} plasma B cells and {} memory generated!\".format(pla_bcs.size(0), mem_bcs.size(0)))\n",
    "        if return_log:\n",
    "            return mem_bcs, mem_labs, pla_bcs, pla_labs, ant_logs\n",
    "        else:\n",
    "            return mem_bcs, mem_labs, pla_bcs, pla_labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MoUkNBDhk-rE",
    "outputId": "e95a6c8c-bb4c-4313-a75e-778f9683f03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models/mnistmodel.pt'\n",
      "=> loaded checkpoint 'models/mnistmodel.pt' (epoch 55)\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"datasets/\"\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "config = utilities.config_to_namedtuple(utilities.get_config('config_mnist.json'))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=DATADIR, train=True, download=False, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "]))\n",
    "mnist_testset = datasets.MNIST(root=DATADIR, train=False, download=False, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset,\n",
    "    shuffle = True,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset,\n",
    "    shuffle = False,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "filename = 'models/mnistmodel.pt'\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "    checkpoint = torch.load(filename,map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(filename, checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "bNnGPJYZmio7",
    "outputId": "9189fe1f-222e-464d-f362-15cdd586d1f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=6272, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GLCOWiVmozT"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "ind_full = np.arange(60000)\n",
    "np.random.shuffle(ind_full)\n",
    "ind_partial = ind_full[:2000]\n",
    "X_train_partial = mnist_trainset.data[ind_partial].unsqueeze(1)/255.\n",
    "y_train_partial = mnist_trainset.targets[ind_partial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ibER6aabmsC0",
    "outputId": "0ae336af-7d12-42b9-f8a6-6bc7bcf6e1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of plain cnn under PGD attacks is: 0.180000\n"
     ]
    }
   ],
   "source": [
    "ind_eval = ind_full[2000:2200]\n",
    "X_eval = mnist_trainset.data[ind_eval].unsqueeze(1)/255.\n",
    "y_eval = mnist_trainset.targets[ind_eval]\n",
    "X_adv = PGD(eps=40/255.,sigma=20/255.,nb_iter=20,DEVICE=DEVICE).attack_batch(model,X_eval.to(DEVICE),y_eval.to(DEVICE),batch_size=64)\n",
    "*_,out = model(X_adv)\n",
    "y_pred_adv = torch.max(out,1)[1]\n",
    "print('The accuracy of plain cnn under PGD attacks is: {:f}'.format((y_eval.numpy()==y_pred_adv.detach().cpu().numpy()).mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "AoHaOQQem5Hb",
    "outputId": "ff8d1298-fc62-49f5-ede4-73d22210cd2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConcatenating results\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cdfa761152ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAISE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_partial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_partial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmem_bcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem_labs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpla_bcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpla_labs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mant_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclonal_expansion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_adv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_eval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-15db4811a1cd>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, X_orig, y_orig, X_hidden, weights, model, input_shape, device, n_class, n_neighbors, query_class, norm_order, fitness_function, sampling_temperature, max_generation, requires_init, mut_range, mut_prob, mut_mode, combine_rate, hybrid_rate, decay, n_population, memory_threshold, plasma_threshold, return_log)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_to_inner_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-15db4811a1cd>\u001b[0m in \u001b[0;36m_transform_to_inner_repr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mX_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_b_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mant_tran\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbc_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "aise = AISE(X_train_partial,y_train_partial,model=model)\n",
    "mem_bcs, mem_labs, pla_bcs, pla_labs, ant_logs = aise.clonal_expansion(X_adv.cpu(),y_eval.numpy(),return_log=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "AISE_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
